# GHL Multi-Location Fitness Franchise Solution

## Project Overview

This solution addresses the challenges of managing leads across a multi-location fitness franchise using GoHighLevel (GHL) as the primary platform, with a custom Node.js backend for advanced analytics and orchestration.

## Table of Contents

1. [System Architecture](#system-architecture)
2. [Database Design](#database-design)
3. [Project Structure](#project-structure)
4. [Setup Instructions](#setup-instructions)
5. [API Documentation](#api-documentation)
6. [GHL Integration](#ghl-integration)
7. [Automation Workflows](#automation-workflows)
8. [Scaling Strategy](#scaling-strategy)

## System Architecture

### High-Level Architecture

```mermaid
graph TB
    subgraph "Lead Sources"
        FB[Facebook Ads]
        WEB[Website Forms]
        WALK[Walk-in Kiosks]
        GOOGLE[Google Ads]
    end
  
    subgraph "GHL Platform"
        MASTER[Master Account]
        subgraph "Sub-Accounts"
            LOC1[Location 1]
            LOC2[Location 2]
            LOC25[Location 25]
        end
        SNAP[Master Snapshot]
    end
  
    subgraph "Custom Backend"
        API[Node.js API]
        QUEUE[Redis Queue]
        CACHE[Redis Cache]
    end
  
    subgraph "Database"
        PG[(PostgreSQL)]
    end
  
    subgraph "External Services"
        MAPS[Google Maps API]
        SMS[Twilio SMS]
        EMAIL[SendGrid]
    end
  
    subgraph "Dashboard"
        ADMIN[Admin Dashboard]
        FRAN[Franchise Dashboard]
        LOC_DASH[Location Dashboard]
    end
  
    FB --> MASTER
    WEB --> MASTER
    WALK --> MASTER
    GOOGLE --> MASTER
  
    MASTER --> API
    LOC1 --> API
    LOC2 --> API
    LOC25 --> API
  
    API --> PG
    API --> QUEUE
    API --> CACHE
    API --> MAPS
    API --> SMS
    API --> EMAIL
  
    API --> ADMIN
    API --> FRAN
    API --> LOC_DASH
  
    SNAP --> LOC1
    SNAP --> LOC2
    SNAP --> LOC25
```

### GHL Structure Overview

```mermaid
graph LR
    subgraph "GHL Account Hierarchy"
        MA[Master Agency Account]
    
        subgraph "Sub-Accounts by Region"
            R1[Region 1 - East Coast]
            R2[Region 2 - West Coast]
            R3[Region 3 - Central]
            R4[Region 4 - South]
            R5[Region 5 - Northwest]
        end
    
        subgraph "Location Sub-Accounts"
            L1[NYC - Manhattan]
            L2[NYC - Brooklyn]
            L3[LA - Beverly Hills]
            L4[LA - Santa Monica]
        end
    end
  
    MA --> R1
    MA --> R2
    MA --> R3
    MA --> R4
    MA --> R5
  
    R1 --> L1
    R1 --> L2
    R3 --> L3
    R3 --> L4
```

## Database Design

### Core Tables Schema

```mermaid
erDiagram
    locations {
        uuid id PK
        string name
        string address
        string city
        string state
        string zip_code
        decimal latitude
        decimal longitude
        string ghl_location_id
        string ghl_sub_account_id
        integer capacity_limit
        boolean active
        timestamp created_at
        timestamp updated_at
    }
  
    leads {
        uuid id PK
        string first_name
        string last_name
        string email
        string phone
        string zip_code
        string source
        string utm_source
        string utm_campaign
        string utm_medium
        uuid assigned_location_id FK
        uuid backup_location_id FK
        string ghl_contact_id
        integer lead_score
        string status
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }
  
    lead_routing_logs {
        uuid id PK
        uuid lead_id FK
        uuid original_location_id FK
        uuid assigned_location_id FK
        string routing_reason
        jsonb routing_data
        timestamp created_at
    }
  
    location_capacity {
        uuid id PK
        uuid location_id FK
        date capacity_date
        integer current_leads
        integer max_capacity
        decimal utilization_rate
        timestamp updated_at
    }
  
    performance_metrics {
        uuid id PK
        uuid location_id FK
        date metric_date
        integer leads_received
        integer leads_contacted
        integer appointments_set
        integer show_ups
        integer conversions
        decimal conversion_rate
        decimal response_time_avg
        timestamp created_at
    }
  
    automation_logs {
        uuid id PK
        uuid lead_id FK
        string automation_name
        string step_name
        string status
        jsonb step_data
        string error_message
        timestamp executed_at
    }
  
    locations ||--o{ leads : "assigned_to"}
    locations ||--o{ location_capacity : "has_capacity"}
    locations ||--o{ performance_metrics : "tracks_performance"}
    leads ||--o{ lead_routing_logs : "routing_history"}
    leads ||--o{ automation_logs : "automation_steps"}
```

## Project Structure

```
.
├── docker-compose.yml
├── Dockerfile
├── docs
│   ├── FitnessFranchiseSolution.md
│   ├── BulkOnboardingAndScalingSolution.md
│   └── solution.md
├── LICENSE
├── package.json
├── public
│   └── dashboard
│       └── index.html
├── README.md
├── setup.sh
├── src
│   ├── database
│   │   ├── connection.js
│   │   ├── models
│   │   │   └── index.js
│   │   └── seed.js
│   ├── middleware
│   │   ├── errorHandler.js
│   │   ├── rateLimiter.js
│   │   └── validation.js
│   ├── modules
│   │   ├── analytics
│   │   │   └── analytics.service.js
│   │   ├── routing
│   │   │   └── routing.service.js
│   │   └── webhooks
│   │       ├── webhook.controller.js
│   │       └── webhook.service.js
│   ├── routes
│   │   ├── analytics.routes.js
│   │   ├── dashboard.routes.js
│   │   ├── location.routes.js
│   │   └── webhook.routes.js
│   ├── server.js
│   ├── services
│   │   └── notificationService.js
│   └── utils
│       ├── geoUtils.js
│       ├── ghlApiClient.js
│       └── logger.js
├── start-dev.sh
└── test-system.js
```

## Setup Instructions

### Prerequisites

- Node.js 18+
- PostgreSQL 14+
- Redis 6+
- Docker (optional)

### Local Development Setup

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd ghl-franchise-system
   ```
2. **Install dependencies**

   ```bash
   npm install
   ```
3. **Setup environment variables**

   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```
4. **Start services with Docker**

   ```bash
   docker-compose up -d postgres redis
   ```
5. **Run database migrations**

   ```bash
   npm run migrate
   npm run seed
   ```
6. **Start the development server**

   ```bash
   npm run dev
   ```

### Environment Variables

```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/ghl_franchise
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=ghl_franchise
DATABASE_USER=ghl_user
DATABASE_PASSWORD=your_password

# Redis
REDIS_URL=redis://localhost:6379
REDIS_HOST=localhost
REDIS_PORT=6379

# GHL API
GHL_API_KEY=your_ghl_api_key
GHL_API_BASE_URL=https://rest.gohighlevel.com/v1
GHL_MASTER_ACCOUNT_ID=your_master_account_id

# External Services
GOOGLE_MAPS_API_KEY=your_google_maps_key
TWILIO_ACCOUNT_SID=your_twilio_sid
TWILIO_AUTH_TOKEN=your_twilio_token
SENDGRID_API_KEY=your_sendgrid_key

# Application
PORT=3000
NODE_ENV=development
JWT_SECRET=your_jwt_secret
LOG_LEVEL=info
```

## GHL Integration Strategy

### 1. Account Structure

- **Master Agency Account**: Central control and lead distribution
- **Regional Sub-Accounts**: Group locations by geographic regions
- **Location Sub-Accounts**: Individual gym locations

### 2. Custom Code Implementation

**Lead Routing Function** (GHL Custom Code Action):

```javascript
// This goes into GHL Custom Code Action
async function intelligentLeadRouting(contactId, zipCode, source, leadScore) {
  const API_BASE = 'https://your-api.com/api/v1';
  
  try {
    // Call our backend API for intelligent routing
    const routingResponse = await fetch(`${API_BASE}/routing/assign`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.API_KEY}`
      },
      body: JSON.stringify({
        contactId,
        zipCode,
        source,
        leadScore,
        timestamp: new Date().toISOString()
      })
    });
  
    const routing = await routingResponse.json();
  
    if (routing.success) {
      // Update contact with assigned location
      await updateContactCustomField(contactId, 'assigned_location_id', routing.locationId);
      await updateContactCustomField(contactId, 'routing_reason', routing.reason);
  
      // Add to location-specific pipeline
      await moveContactToPipeline(contactId, routing.pipelineId, routing.stageId);
  
      // Trigger location-specific automation
      await triggerAutomation(contactId, routing.automationId);
  
      return {
        success: true,
        locationId: routing.locationId,
        reason: routing.reason
      };
    } else {
      // Fallback to default location
      await updateContactCustomField(contactId, 'routing_error', routing.error);
      return { success: false, error: routing.error };
    }
  } catch (error) {
    console.error('Lead routing error:', error);
    // Implement fallback logic
    return { success: false, error: error.message };
  }
}
```

### 3. Webhook Processing

Our backend processes GHL webhooks for:

- Contact creation/updates
- Pipeline stage changes
- Appointment bookings
- SMS/Email interactions

## Lead Routing Automation Workflow

```mermaid
flowchart TD
    START[Lead Captured] --> EXTRACT[Extract Zip Code & Source]
    EXTRACT --> GEOCODE[Geocode to Lat/Long]
    GEOCODE --> FIND_CLOSEST[Find 3 Closest Locations]
    FIND_CLOSEST --> CHECK_CAPACITY{Primary Location Has Capacity?}
  
    CHECK_CAPACITY -->|Yes| ASSIGN_PRIMARY[Assign to Primary Location]
    CHECK_CAPACITY -->|No| CHECK_SECONDARY{Secondary Location Has Capacity?}
  
    CHECK_SECONDARY -->|Yes| ASSIGN_SECONDARY[Assign to Secondary Location]
    CHECK_SECONDARY -->|No| CHECK_TERTIARY{Tertiary Location Has Capacity?}
  
    CHECK_TERTIARY -->|Yes| ASSIGN_TERTIARY[Assign to Tertiary Location]
    CHECK_TERTIARY -->|No| OVERFLOW[Add to Overflow Queue]
  
    ASSIGN_PRIMARY --> UPDATE_GHL[Update GHL Contact]
    ASSIGN_SECONDARY --> UPDATE_GHL
    ASSIGN_TERTIARY --> UPDATE_GHL
    OVERFLOW --> MANUAL_REVIEW[Manual Review Queue]
  
    UPDATE_GHL --> NOTIFY_TEAM[Notify Assigned Team]
    NOTIFY_TEAM --> TRIGGER_AUTOMATION[Start Location Automation]
    TRIGGER_AUTOMATION --> LOG_ROUTING[Log Routing Decision]
  
    MANUAL_REVIEW --> ADMIN_NOTIFY[Notify Admin]
  
    LOG_ROUTING --> END[Complete]
    ADMIN_NOTIFY --> END
```

## API Endpoints

### Core API Routes

```javascript
// Lead Management
POST   /api/v1/leads                    # Create new lead
GET    /api/v1/leads                    # List leads with filters
GET    /api/v1/leads/:id                # Get lead details
PUT    /api/v1/leads/:id                # Update lead
DELETE /api/v1/leads/:id                # Delete lead

// Lead Routing
POST   /api/v1/routing/assign           # Assign lead to location
GET    /api/v1/routing/logs             # Get routing logs
POST   /api/v1/routing/reassign/:id     # Reassign lead

// Location Management
GET    /api/v1/locations                # List all locations
POST   /api/v1/locations               # Create location
GET    /api/v1/locations/:id           # Get location details
PUT    /api/v1/locations/:id           # Update location
DELETE /api/v1/locations/:id           # Delete location

// Capacity Management
GET    /api/v1/locations/:id/capacity   # Get location capacity
PUT    /api/v1/locations/:id/capacity   # Update capacity limits
GET    /api/v1/capacity/overview        # System-wide capacity

// Analytics
GET    /api/v1/analytics/dashboard      # Dashboard metrics
GET    /api/v1/analytics/performance    # Performance by location
GET    /api/v1/analytics/conversion     # Conversion rates
GET    /api/v1/analytics/sources        # Lead source analysis

// Webhooks
POST   /api/v1/webhooks/ghl            # GHL webhook endpoint
POST   /api/v1/webhooks/facebook       # Facebook webhook
GET    /api/v1/webhooks/logs           # Webhook processing logs

// Bulk Operations
POST   /api/v1/bulk/locations          # Bulk location creation
POST   /api/v1/bulk/import             # Bulk data import
GET    /api/v1/bulk/status/:jobId      # Check bulk job status
```

## Scaling Strategy for 100+ Locations

### 1. Technical Modifications

**Database Partitioning**:

```sql
-- Partition leads table by region for better performance
CREATE TABLE leads_region_1 PARTITION OF leads 
FOR VALUES IN ('east', 'southeast', 'northeast');

CREATE TABLE leads_region_2 PARTITION OF leads 
FOR VALUES IN ('west', 'southwest', 'northwest');
```

**Caching Strategy**:

- Redis caching for location lookups
- Geographic boundary caching
- Capacity status caching with 5-minute TTL

**Queue-based Processing**:

```javascript
// Queue lead processing for high volume
const leadQueue = new Queue('lead processing', {
  redis: redisConnection,
  defaultJobOptions: {
    removeOnComplete: 100,
    removeOnFail: 50,
  }
});

leadQueue.process(10, async (job) => {
  return await processLeadRouting(job.data);
});
```

### 2. Bulk Onboarding Automation

**Location Creation Script**:

```javascript
// scripts/bulk-onboard.js
async function bulkOnboardLocations(locationData) {
  const jobs = locationData.map(location => ({
    name: 'onboard-location',
    data: location,
    opts: { delay: Math.random() * 5000 } // Stagger requests
  }));
  
  await onboardingQueue.addBulk(jobs);
}
```

**GHL Snapshot Deployment**:

- Automated snapshot application to new sub-accounts
- Custom field mapping per location
- Pipeline and automation customization

### 3. Data Integrity During Transition

**Migration Strategy**:

```javascript
// Gradual migration with rollback capability
async function migrateLocationToNewSystem(locationId) {
  const transaction = await db.beginTransaction();
  
  try {
    // 1. Create backup
    await backupLocationData(locationId, transaction);
  
    // 2. Migrate data
    await migrateLocationContacts(locationId, transaction);
  
    // 3. Update routing rules
    await updateRoutingRules(locationId, transaction);
  
    // 4. Verify integrity
    await verifyDataIntegrity(locationId, transaction);
  
    await transaction.commit();
  
  } catch (error) {
    await transaction.rollback();
    await notifyAdminOfFailure(locationId, error);
    throw error;
  }
}
```

### 4. Performance Optimizations

**Database Optimizations**:

```sql
-- Optimized indexes for routing queries
CREATE INDEX CONCURRENTLY idx_leads_zip_created 
ON leads (zip_code, created_at DESC);

CREATE INDEX CONCURRENTLY idx_locations_geo 
ON locations USING GIST (ST_Point(longitude, latitude));

-- Materialized views for analytics
CREATE MATERIALIZED VIEW location_performance_summary AS
SELECT 
  location_id,
  DATE(created_at) as metric_date,
  COUNT(*) as total_leads,
  AVG(lead_score) as avg_lead_score,
  COUNT(CASE WHEN status = 'converted' THEN 1 END) as conversions
FROM leads
GROUP BY location_id, DATE(created_at);
```

**API Rate Limiting**:

```javascript
// Implement intelligent rate limiting for GHL API
const rateLimiter = new RateLimiterRedis({
  storeClient: redisClient,
  keyPrefix: 'ghl_api',
  points: 100, // requests
  duration: 60, // per 60 seconds
});
```

## Monitoring and Alerting

### Key Metrics to Track

```javascript
// Performance monitoring
const metrics = {
  leadRoutingTime: histogram({
    name: 'lead_routing_duration_seconds',
    help: 'Time taken to route a lead'
  }),
  
  capacityUtilization: gauge({
    name: 'location_capacity_utilization',
    help: 'Current capacity utilization by location'
  }),
  
  routingErrors: counter({
    name: 'routing_errors_total',
    help: 'Total routing errors'
  })
};
```

### Health Checks

```javascript
// Health check endpoints
app.get('/health', async (req, res) => {
  const health = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    services: {
      database: await checkDatabase(),
      redis: await checkRedis(),
      ghl_api: await checkGHLConnection(),
      queue: await checkQueueHealth()
    }
  };
  
  const isHealthy = Object.values(health.services)
    .every(service => service.status === 'healthy');
  
  res.status(isHealthy ? 200 : 503).json(health);
});
```

## Deployment

### Production Deployment with Docker

```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    build: .
    environment:
      - NODE_ENV=production
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 3
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - app
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf
  
  postgres:
    image: postgres:14
    environment:
      POSTGRES_DB: ghl_franchise
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:6-alpine
    volumes:
      - redis_data:/data
```

## Testing Strategy

### Unit Tests

```javascript
// tests/unit/routing.test.js
describe('Lead Routing Service', () => {
  test('should assign lead to closest available location', async () => {
    const lead = { zipCode: '10001', source: 'facebook' };
    const result = await routingService.assignLead(lead);
  
    expect(result.locationId).toBeDefined();
    expect(result.reason).toBe('closest_available');
  });
});
```

### Integration Tests

```javascript
// tests/integration/api.test.js
describe('API Integration', () => {
  test('webhook processing end-to-end', async () => {
    const webhookPayload = mockGHLWebhook();
    const response = await request(app)
      .post('/api/v1/webhooks/ghl')
      .send(webhookPayload)
      .expect(200);
  
    // Verify lead was processed and routed
    const lead = await Lead.findByGHLContactId(webhookPayload.contact_id);
    expect(lead.assigned_location_id).toBeDefined();
  });
});
```

## Documentation

### API Documentation

- Complete OpenAPI/Swagger specification
- Postman collection for testing
- Example requests and responses

### Operational Runbooks

- Deployment procedures
- Troubleshooting guides
- Performance tuning tips
- Backup and recovery procedures

## Next Steps

1. **Phase 1**: Core routing system (Weeks 1-2)
2. **Phase 2**: Analytics dashboard (Weeks 3-4)
3. **Phase 3**: Bulk onboarding tools (Weeks 5-6)
4. **Phase 4**: Advanced optimizations (Weeks 7-8)

This architecture provides a solid foundation for scaling from 25 to 100+ locations while maintaining data integrity, performance, and operational efficiency.

---
